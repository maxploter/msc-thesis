PRESENTATION_CONTENT_MARKDOWN = '''
# Slide 1
## Metadata
### Layout
Pildita avaslaid
### Placeholder keys
#### Title
12
#### Presenter
13
#### Supervisor
14
## Title
Eyes Wide Shut: Analyzing Object Detection Performance Under Degraded Sensor Input Scenarios
## Presenter
Maksim Ploter
## Supervisor
Tambet Matiisen, MSc
## Presenter notes
* Welcome everyone. My name is Maksim Ploter, and this is the presentation of my Master's thesis, "Eyes Wide Shut: Analyzing Object Detection Performance Under Degraded Sensor Input Scenarios."
* I'd like to thank my supervisor, Tambet Matiisen, for his guidance.
* (Briefly state the date if relevant, e.g., "Today is May 23, 2025.")

---

# Slide 2
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
## Title
Introduction: Goal
## Content
* Autonomous Driving Systems promise safer roads, better traffic flow, and reduced environmental impact.
* Society of Automotive Engineers (SAE) International’s standard stipulates stringent safety requirement:
  * 
  * Perform the complete Dynamic Drivable Task Fallback under a performance-related system failure
* Autonomous Driving Systems 

* A key challenge: ADS perception stacks, reliant on multi-sensor data, are vulnerable to failures.
  * This thesis investigates two specific failure modes: complete sensor failure and non-deterministic input availability.
* Such failures can lead to catastrophic accidents, undermining public trust and hindering ADS adoption.
* **The Need**: Perception models that are robust to these failures and can support multi-modal hardware are crucial for safety-critical applications like ADS.
## Presenter notes

% Actuality

Autonomous Driving System (ADS) is defines as the hardware and software collectively capable of performing the entire 
Dynamic Driving Task on a sustained basis. The actuality of Autonomous Driving Systems lies in their promise to deliver
 safer roads, better traffic flow, and a reduced environmental impact.
System failures in Autonomous Driving System can lead to catastrofic accidents and undermine public trust.

In the scope of the thesis two system failures were identified.
The first is complete sensor filure. Autonomous Driving System is desidned to function reliably in Operational Design Domain, 
which encopasses a wide range of factors, including, but not limited to, roadway types, georgraphical constraints, speed limimtations, 
and envrionmental considtions. In order to construct the detailed model of the environment ADS is equiped with a comprihensive suite of sensors.
Given the reliance on a complex sensor suite and operation in diverse environments, the potential
for sensor failures presents.

The second is non-deterministic sensor input availability. ADS is equped with software such as Robot Operating System. 
Given   



Autonomous Driving System Dynamic Driving Tasks include various tasks, in the scope of the thesis there's an interest 
in a critical set of subtasks of the DDT. 


Autonomous Driving System desidned to function reliably in Operational Design Domain, which encompass a wide range of factors, including,
but not limited to, roadway types, geographical constraints, speed limitations, and environmental conditions.
Autonomous Driving System is equipped with a comprehensive suite of sensors.
The ADS’s computational hardware and software stack processes data streams generated by its
diverse sensor array. 


Operational Design Domain (ODD). The ODD specifies the precise conditions under which a given ADS is
designed to function reliably. These conditions encompass a wide range of factors, including,
but not limited to, roadway types, geographical constraints, speed limitations, and environmental
conditions [1].
Broadly, ADS architectures are categor


Object and Event Detection and Response is also known as perception


catorstorfic accidents and undermine public trust.


Therefore, ADS need perception models that support multi-modal hardware and are robust to the failures.


Dynamic Driving Tasks include various tasks, in the scope of the thesis there's an interest 
in a critical set of subtasks of the DDT is Object and Event Detection and Response is also known as perception.  


Their perception stacks, reliant on multi-sensor data, are vulnerable to hardware and software failures 
like complete sensor failure or non-deterministic input availability, the two failure modes specifically investigated in this thesis. Such failures can lead to catastrophic accidents, undermining public trust \cite{yurtseverSurveyAutonomousDriving2020}.


* Start by highlighting the promise of Autonomous Driving Systems – safer roads, efficiency.
* Immediately introduce the core problem: reliability, especially of the perception system.
* Emphasize the vulnerability of multi-sensor systems to failures. Clearly state the two failure modes this thesis focuses on: *complete sensor failure* and *non-deterministic input availability*.
* Connect these failures to real-world consequences: accidents, loss of public trust.
* This sets the stage for why this research is important: the need for robust perception models for safe ADS.

---

# Slide 3
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
## Title
Introduction: Research Tasks
## Content
* **Overall Goal**: To contribute to the development of more resilient perception systems crucial for the safe deployment of ADS.
* **Main Research Tasks**:
  1. **Develop Novel Architectures**: Introduce two novel recurrent architectures, the Recurrent Perceiver (RPerceiver) and its multi-modal variant (RPerceiverMM), designed for processing diverse, high-dimensional sequential inputs like video for object detection.
  2. **Enhance Robustness**: Propose and investigate specific training procedures (e.g., input dropout, shuffling) to simulate sensor failures and non-deterministic data availability, aiming to improve model robustness.
  3. **Evaluate Performance**:
     * Introduce a novel benchmark dataset, "detection-moving-mnist-easy," for evaluating bounding box detection and center point prediction.
     * Assess the object detection performance and robustness of the proposed models against simulated sensor failure scenarios.
## Presenter notes
* Clearly state the overarching goal: developing more resilient perception systems for ADS safety.
* Break down the goal into specific research tasks. This provides a roadmap for your work.
* **Task 1**: Mention the novel architectures (RPerceiver and RPerceiverMM) and their purpose (handling complex sequential data).
* **Task 2**: Highlight the focus on robustness through specific training procedures (dropout, shuffling) and their link to simulating real-world failures.
* **Task 3**: Explain how performance was evaluated – the new dataset and the assessment of both detection accuracy and robustness.

---

# Slide 4
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
## Title
Introduction: Thesis Structure
## Content
* **1. Introduction**: Problem statement, motivation, goals, and contributions.
* **2. Background**:
  * Autonomous Driving Systems (SAE Levels, safety, ODD, architectures).
  * Video Object Detection (evolution from frame-by-frame to Transformer-based models).
  * General Purpose Perceiver Model (architecture, cross-attention, limitations).
* **3. Methods**:
  * Proposed Models: RPerceiver & RPerceiverMM architectures.
  * Dataset: "detection-moving-mnist-easy".
  * Training Procedures for Robustness: Dropout and Shuffle.
  * Loss Function and Metrics.
* **4. Experiments**: Training setup, comparative analysis, and ablation studies focusing on robustness.
* **5. Discussion**: Limitations and future research directions.
* **6. Conclusion**: Summary of findings and contributions.
## Presenter notes
* Briefly walk the audience through the structure of your thesis (and thus, the presentation).
* This helps them follow your logic and understand where different pieces of information fit.
* Don't spend too much time here; it's just a guide.

---

# Slide 5
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
8
##### Left
1
##### Height
9
## Title
Methods: Perceiver
## Content
The Perceiver uses a cross-attention module to project a high-dimensional input byte array to a fixed-dimensional latent bottleneck (the number of input indices M is much larger than the number of latent indices N) before processing it using a deep stack of Transformer-style self-attention blocks in the latent space. The Perceiver iteratively attends to the input byte array by alternating cross-attention and latent self-attention blocks
## Image
![Perceiver Architecture Diagram](/content/msc-thesis/english/figures/figure_background_perceiver_architecture.png)
## Presenter notes

The figure in the slide depicts Perceiver architecture. The Perceiver was introduced as general-purpose architecture that is capable of 
processing different types of high-dimensional inputs such as inputs such as images, video, audio, point clouds. 
The model was build upon Transformer achitecture. Its architecture consists of two primary components: 
(i) a cross-attention module and 
(ii) a self-attention.

The challange in attention it is quadratic computational and memory complexity with respect to the input sequence length.
The Perceiver mitigates the quadratic complexity bottleneck by employing its cross-attention module. This
module introduces an asymmetry into the attention operation when applied directly to the inputs.

---

# Slide 6
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Methods: Recurrent Perceiver (RPerceiver)
## Content
The Recurrent Perceiver (RPerceiver) architecture processes inputs along the time dimension by propagating the latent array between time steps.
The latent array's dimension N can be seen as representing the number of objects the RPerceiver tracks, and D as the number of attributes for each object (position, color, speed, etc.). 

## Image
![RPerceiver Architecture Diagram](/content/msc-thesis/english/figures/figure_methods_recurrent_perceiver.png)
## Presenter notes

The figure in the slide depicts the Recurrent Perceiver architecture proposed in the thesis.

The original Perceiver arhitecture was re-engineered by incorporating a time dimention. 
As we can see in the figure this architecture is unrolled in depth and time.

The intuition behind the RPerceiver architecture for object detection is that the variable N, a dimension of the latent array, represents the number of objects the RPerceiver tracks, while D represents the number of features for each object (e.g., position, dimension, color, speed, etc.). In order to revalidate the existence of an object across different modalities by utilizing cross-attention to match its features with sensor input. Periodically,
the system must initiate tracking for new objects within its N available slots, necessitating a mechanism to monitor slot utilization.

---

# Slide 7
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Methods: Recurrent Perceiver Multi-Modal (RPerceiverMM)
## Content
TODO
## Image
![RPerceiverMM Architecture Diagram](/content/msc-thesis/english/figures/figure_methods_recurrent_perceiver_mm.png)
## Presenter notes
The figure in the slide depicts the variant of Recurrent Perceiver capable of processing multi-modal input. The architecture employs sensor-specific cross-attention. In the figure you can see modality dimension and cross-attention weights dedicated to the sensor modality. The scope of the thesis includes only camera sensors.

---

# Slide 8
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Methods: Complete Model Architecture
## Content
Complete architecture of the model, including RPerceiver, Backbone, and Detection Heads.
Input frames are processed by a Backbone network to extract a feature map. This flattened
feature map, along with a latent array propagated from the previous time step, is fed into a
Recurrent Perceiver (RPerceiver). The RPerceiver’s output embedding is then used by
Prediction Heads to determine class labels and object positions for the current frame.
## Image
![Complete Model Architecture Diagram](/content/msc-thesis/english/figures/figure_methods_recurrent_perceiver_complete.png)
## Presenter notes

The figure in the slide depicts the complete architecture of the model of processing multi-modal input.
In addition to the RPerceiver module, a CNN backbone and detection heads were utilized
* **Intuition**: The latent array's dimension N can be seen as representing the number of objects the RPerceiver tracks, and D as the number of attributes for each object (position, color, speed, etc.).


---

# Slide 9
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Methods: Training for Robustness
## Content
Diagram of the dropout procedure. Timestep 1 shows normal operation. Timestep 2 illustrates a dropout event: the input feature map and the cross-attention block are shown faded, indicating that this sensor's data is dropped. Consequently, the cross-attention step, which incorporates new sensor information (K, V), is skipped. However, the latent array is still updated by the self-attention mechanism, demonstrating the model’s reliance on its internal memory when an input is missing. Intuitively, self-attention acts like a ’propagate forward’ step in a tracker: it updates the object’s presumed state based on prior motion even without current sensor input. This internal prediction maintains continuity and can be corrected by cross-attention when new sensor data becomes available and is processed.
## Image
![Dropout Mechanism Illustrated](/content/msc-thesis/english/figures/figure_methods_recurrent_perceiver_with_dropout.png)
## Presenter notes
As it was mentioned previously ADS faces  

* Reiterate the motivation for these training procedures: making models robust to real-world sensor issues.
* Explain **Dropout**:
  * What it simulates (complete sensor failure).
  * How it works (dropping inputs in the second half of the sequence, increasing probability).
  * The effect on the model (skips cross-attention for that sensor, relies on self-attention/memory).
  * Refer to the dropout diagram (Figure 11) to illustrate.
* Explain **Shuffle**:
  * What it simulates (non-deterministic input order from middleware).
  * How it works (randomly permuting sensor input order per timestep).
  * Specify it's for multi-sensor setups.
* Mention the baseline model (trained without these).

---

# Slide 10
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Methods: Dataset
## Content
Example of 12 frames from the sequence. Ground truth, shown in red, indicates the digit center point, bounding box and a class label.
## Image
![figure_methods_dataset_detection_mmnist_sequence](/content/msc-thesis/english/figures/figure_methods_dataset_detection_mmnist_sequence.png)
## Presenter notes
As a second contribution to the thithis, moving mmnist dataset for object detection was generated.

---

# Slide 11
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
8
##### Left
1
##### Height
7
## Title
Experiments and Results: Comparison Analysis (1)
## Content
Comparison with the baseline still image detector YOLOv8n. RPerceiver achieves slightly better mAP50 and mAP75, but shows worse mAP50−95 results. However, RPerceiver achieves these results with significantly fewer parameters and lower computational cost.
## Image
![table_experiments_comparison_analysis](/content/msc-thesis/english/figures/table_experiments_comparison_analysis.png)
## Presenter notes

The table in the slide presents the comparison analysis between the Recurrent Perceiver and a baseline model still image detector YOLOv8n. RPerceiver achieves slightly better mAP50 and mAP75, but shows worse mAP50−95 results.

---

# Slide 12
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Experiments and Results: Comparison Analysis (2)
## Content
TODO
## Image
![figure_methods_val_batch2_pred_YOLO](/content/msc-thesis/english/figures/figure_methods_val_batch2_pred_YOLO.jpg)
## Presenter notes


---

# Slide 13
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
## Title
Experiments and Results: Comparison Analysis (3)
## Content
TODO
## Image
![figure_methods_val_batch2_pred_recurrent_perceiver](/content/msc-thesis/english/figures/figure_methods_val_batch2_pred_recurrent_perceiver.jpg)
## Presenter notes


---

# Slide 14
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
### Shapes
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Experiments and Results: Comparison Analysis (4)
## Content
Comparative analysis on specific scenarios: object overlaps (’Overlap’) and proximity to image borders (’Border’). The data indicates that the still-image detector YOLOv8n achieves higher accuracy on overlapping objects. In contrast,
RPerceiver significantly outperforms YOLOv8n on border cases, supporting the hypothesis that it effectively leverages temporal information from the video sequence.
## Image
![figure_methods_val_batch2_pred_recurrent_perceiver](/content/msc-thesis/english/figures/table_experiments_comparison_analysis_challanging_cases.png)

## Presenter notes

---

# Slide 15
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
#### Image
##### Type
picture
##### Top
1
##### Left
1
##### Height
15
## Title
Experiments and Results: Ablation Study
## Content
Comparison of RPerceiverMM (RPMM) variants under the multi-view configuration across different evaluation procedures: default, shuffle, blind, and combined blind, shuffle. Model notations indicate training procedures: ’(s)’ for shuffle training, ’(d)’ for dropout training, and ’(d, s)’ for combined dropout and shuffle training. Metrics shown are Average Displacement Error (ADE), calculated over the second half of the sequence, Final Displacement Error (FDE), calculated for the final frame, and the number of model parameters in millions (Params (M)). The results highlight trade-offs: baseline RPMM performs best under defaultconditions. While these training procedures introduce a small performance penalty in the defaultevaluation, they provide substantial improvements under performance-degrading evaluation strategies. Models trained with shuffle (s) excel in the shuffle evaluation, while dropout-trained models (d) show superior robustness in the blind scenario. The combined training (d, s) yields the most robust performance under the combined blind, shuffle condition, demonstrating the effectiveness of targeted training strategies for specific failure modes. Interestingly, RPMM (d) also shows notable robustness under the shuffle evaluation, despite not being explicitly trained for this condition.
## Image
![table_experiments_ablation_study_multi](/content/msc-thesis/english/figures/table_experiments_ablation_study_multi-view.png)

## Presenter notes
* Acknowledge the limitations of your work honestly. This shows critical thinking.
  * RPerceiver's precision at high IoUs.
  * The simplicity of the dataset.
* Propose concrete future research directions that stem from these limitations or open new questions.
  * Improving precision (model capacity, backbones).
  * Making the dataset more complex and realistic.
  * Delving deeper into how RPerceiver internally represents and tracks objects (using MOT metrics). This links back to the initial intuition about the latent array.

---

# Slide 16
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
## Title
Conclusion
## Content
* **Main Contributions**:
  1. Introduced two novel recurrent architectures: **RPerceiver** and **RPerceiverMM**, adapted from Perceiver \[17\] for sequential and multi-modal high-dimensional data like video.
  2. Generated a novel benchmark dataset, **"detection-moving-mnist-easy,"** for evaluating video object detection (bounding box & center point).
  3. Proposed and evaluated specific training procedures (**dropout** and **shuffle**) to enhance model robustness against simulated sensor failures and non-deterministic data availability, critical for ADS.
* **Key Findings**:
  * RPerceiver showed competitive mAP scores against YOLOv8n with significantly fewer parameters and lower GFLOPS, particularly excelling with objects near frame borders (leveraging temporal information).
  * Training with **dropout** significantly improved RPerceiver's performance under simulated complete sensor failure in single-view scenarios.
  * For multi-view RPerceiverMM, **shuffle training** enhanced robustness to input order changes, **dropout training** to sensor failure, and **combined training** offered the best resilience under concurrent failure modes.
  * While robustness training incurred a minor performance penalty under normal conditions, the gains in resilience against common sensor issues are substantial for ADS safety.
* This work contributes to developing more resilient perception systems, vital for the safe deployment of Autonomous Driving Systems. The code is open-sourced.
## Presenter notes
* Summarize your main contributions clearly and concisely. Use the list from your thesis.
* Reiterate the most important findings.
  * RPerceiver's efficiency and strength on border cases.
  * Effectiveness of dropout for single-view robustness.
  * Effectiveness of shuffle, dropout, and combined training for multi-view robustness.
  * The trade-off between robustness and default performance, but emphasize the importance of resilience for ADS.
* End with a strong concluding statement about the impact of your work (contributing to safer ADS).
* Mention that the code is open-sourced.

---

# Slide 17
## Metadata
### Layout
Pealkiri ja sisu (nt graafik)
### Placeholder keys
#### Title
0
#### Content
10
## Title
Thank You & Questions
## Content
* **Acknowledgements**:
  * My supervisor, Tambet Matiisen, for invaluable guidance and support.
  * The University of Tartu for the excellent research environment and HPC resources.
  * My family for their unwavering support and encouragement.
* **Code Availability**:
  * The code for this research is open-sourced and available at:
    * https://github.com/maxploter/MultiSensorDropout/
* **Questions?**
## Presenter notes
* Express gratitude to those who supported you (supervisor, university, family).
* Provide the link to your open-sourced code again.
* Open the floor for questions.
* Be prepared to answer questions about any part of your thesis.
'''