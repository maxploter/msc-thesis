\section{Discussion} \label{Discussion}

One of the limitations discovered during this research is that the RPerceiver's precision is fairly poor at higher levels of Intersection over Union (IoU). Comparative analysis proved this, showing that YOLOv8n performed better than RPerceiver at $mAP@0.5:0.95$, despite both models achieving comparable mAP scores at easier IoU metrics. This suggests that while RPerceiver can identify objects at a basic level, its ability to accurately define their boundaries is less refined than YOLOv8n when stricter overlap criteria are applied. These findings indicate that further investigation is needed to enhance RPerceiver's precision. Potential directions for future work could involve increasing the RPerceiver model's capacity to be more comparable to that of YOLOv8n, for instance by increasing its depth of the RPerceiver or experimenting with different backbone architectures, which might improve its ability to learn finer details. This is particularly relevant as one of the findings regarding transformer based object detection model DETR \cite{carionEndtoEndObjectDetection2020} was its lower performance on small objects, where authors anticipated that future work could address this limitation, perhaps in a manner similar to how the development of Feature Pyramid Networks (FPN) \cite{linFeaturePyramidNetworks2017} improved performance on objects of varying scales in other architectures \cite{carionEndtoEndObjectDetection2020}.

Another limitation of this study revolves around the "detection-moving-mnist-easy" dataset. While intentionally simplified for controlled experiments, it does not fully represent all the challenges presented by real-world video data. In particular, the dataset is missing effects such as motion blur and objects entering the video frame. Therefore, another important direction for future research is to increase the complexity of the dataset. Introducing these real-world challenges could provide more nuanced insights into the comparative analysis of different object detection models and further highlight the strengths and weaknesses of architectures like RPerceiver.

Finally, an idea for a future ablation study is to investigate the core intuition behind the RPerceiver architecture for object detection. The hypothesis is that the variable $N$, representing a dimension of the latent array, corresponds to the number of objects the RPerceiver actively tracks, while $D$ represents the number of features for each object, as objects appear and disappear, the system must periodically initiate tracking for new objects within its $N$ available slots, which necessitates a mechanism to monitor slot utilization. To explore this, one could incorporate metrics commonly used in multi-object tracking tasks (MOT). This could involve treating the latent array index as a tracked object ID to observe whether a detected object is consistently tracked by the same latent array vector in time or if the object's identity shifts from one latent vector to another as the object moves through the frame scene. Such an investigation could validate the architectural design choices and provide deeper understanding of RPerceiver's internal object representation and tracking capabilities.
