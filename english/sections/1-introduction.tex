\section{Introduction} \label{Introduction}

% Justification for the choice of topic
% actuality

Autonomous Driving Systems (ADS) hold immense promise, envisioning a future of transportation with enhanced road safety, improved traffic flow, and reduced environmental impact \cite{litmanAutonomousVehicleImplementationb}. Achieving this vision requires ADS to operate reliably under a wide spectrum of diverse and often challenging environmental conditions. This operational requirement necessitates a sophisticated perception stack, heavily reliant on data integrated from multiple sensors. Crucially, the hardware components of this stack are susceptible to system failures, including non-deterministic sensor input availability and complete sensor outages, the two failure modes specifically investigated in this thesis. Such failures in the perception system can have catastrophic consequences, potentially leading to accidents and undermining public trust in autonomous technology \cite{}. Therefore, ADS necessitate perception models that possess two critical requirements: inherent capability to support the multi-modal hardware stack typical of these systems and robustness against sensor failure.

% Overview Theoretical Background -- background information to contextualize the problem
% review of state of the art solutions
The task of object detection is central to the perception capabilities of ADS and has seen significant advancements driven by deep learning. While video sequences offer rich spatio-temporal information compared to static images, they also introduce unique challenges for object detection, such as motion blur, varying object appearances, and frequent occlusions. Direct application of standard still-image detectors is often insufficient to address these complexities \cite{redmonYouOnlyLook2016}. Consequently, various specialized video object detection techniques have emerged, broadly falling into categories based on how they incorporate temporal information. One category involves applying post-processing heuristics like Sequence NMS \cite{hanSeqNMSVideoObject2016} or flow-guided feature aggregation \cite{kangTCNNTubeletsConvolutional2018, kangObjectDetectionVideo2016} to refine outputs from static detectors, aiming for temporal consistency but often lacking end-to-end integration. Another category directly models temporal dependencies during training, utilizing additional components like LSTM networks \cite{Lu_2017_ICCV} or spatio-temporal memory modules (e.g., STMM with ConvGRU) \cite{xiaoVideoObjectDetection2018} to explicitly capture motion and appearance dynamics across frames. More recently, Transformer-based architectures like DETR and its variants \cite{carionEndtoEndObjectDetection2020,} have shown promise by reformulating the task.

% Problem statement -- if necessary, it should include the posed hypothesis/hypotheses, research questions, and subject of research

Despite these advancements, a significant gap remains concerning the development of truly generalist perception architectures suitable for the demands of ADS. Many existing state-of-the-art models function as specialists, often built upon architectures with strong inductive biases tailored for specific data types, like 2D video frames processed by CNNs or specific RNN structures. This specialization limits their flexibility and inherent capacity to handle the diverse range of sensor modalities (e.g., LiDAR point clouds, radar returns, thermal imagery alongside video) commonly employed in ADS perception stacks. These models typically lack native mechanisms to process and effectively fuse information from such heterogeneous, high-dimensional inputs without resorting to complex, hand-tuned, multi-component systems. Consequently, building a unified and robust understanding of the driving environment from multi-modal data remains a challenge. This underscores the pressing need for more general-purpose perception architectures, which capable of processing diverse data types without domain-specific assumptions and scale efficiently to large inputs, paving the way for more versatile and robust ADS perception.


% Purpose of the Thesis -- overall aim and objective of the research, "why" of the researchâ€”why are you conducting this study?

% novelty

To address these limitations, this thesis introduces novel recurrent architectures, the Recurrent Perceiver (RPerceiver) and its multi-modal variant, Recurrent Perceiver Multi-Modal (RPerceiverMM). These models are designed as highly generalist recurrent modules, inspired by the Perceiver architecture \cite{jaeglePerceiverGeneralPerception2021}, capable of processing diverse and high-dimensional sequential inputs, including multi-sensor data streams. We present a comprehensive training framework and experimental setup specifically designed to assess not only the object detection performance but also the robustness of these architectures against simulated sensor failure scenarios, demonstrating their potential for safety-critical applications like ADS. Our main contributions are as follows:

\begin{itemize}
    \item We propose a Recurrent Perceiver architecture that, when unrolled in time, can be interpreted as a recurrent neural network (RNN). Furthermore, the model supports multiple sensory inputs.
    \item We introduce a custom-created benchmark dataset, which we call "detection-moving-mnist-easy", designed to evaluate performance on two distinct tasks: bounding box detection and object center point (keypoint) prediction.    
    \item We propose specific training procedures (e.g., input dropout, shuffling) and evaluation protocols designed to simulate and assess model robustness against potential hardware and software failures, such as complete sensor outages or non-deterministic input availability in single-sensor and multi-sensor setups.
\end{itemize}

This thesis is organized as follows: section \ref{Background} provides background information on autonomous driving system architecture, overviews state of the art video object detection approaches, and introduces the original Perceiver model architecture \cite{jaeglePerceiverGeneralPerception2021}. Section \ref{Methods} presents the novel Recurrent Perceiver architecture, introduces the benchmark used for training and testing, and explains the training procedure. Section \ref{Experiments} explains the experiments and presents the results.

% a short overview of appendices including the content of attached materials
% TODO

% TODO: Question where should i put it?
% This thesis was written using the Overleaf1 text editor. The text was checked with the
% Grammarly2 writing assistant to catch typos and other grammatical errors.