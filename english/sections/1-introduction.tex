\section{Introduction} \label{Introduction}

% Justification for the choice of topic
% actuality

Autonomous Driving Systems (ADS) promise safer roads, better traffic flow, and reduced environmental impact \cite{litmanAutonomousVehicleImplementationb}. However, achieving this requires ADS to operate reliably under diverse and challenging conditions. Their perception stacks, reliant on multi-sensor data, are vulnerable to hardware failures like sensor outages or non-deterministic input availability—the focus of this thesis. Such failures can lead to catastrophic accidents, undermining public trust \cite{yurtseverSurveyAutonomousDriving2020}. Thus, ADS need perception models that support multi-modal hardware and are robust to sensor failure.

% Overview Theoretical Background -- background information to contextualize the problem
% review of state of the art solutions
Object detection is a fundamental perception task for Autonomous Driving Systems, a domain that has been significantly advanced by deep learning. Video data, while affording rich spatio-temporal information, introduces distinct challenges such as motion blur, variations in object appearance, and occlusions. The aggregation of temporal information can be accomplished through several methods. Initial approaches frequently concentrated on postprocessing the outputs of static image detectors. These methods employed techniques like non-maximum suppression Seq-NMS~\cite{hanSeqNMSVideoObject2016} to link detections or utilized tracking and optical flow \cite{kangObjectDetectionVideo2016, kangTCNNTubeletsConvolutional2018} to propagate information for temporal consistency. However, these techniques primarily address symptoms because the core detection mechanism does not learn from temporal data, and the methods are not end-to-end. This limitation restricts recovery from occlusions or substantial appearance shifts. To mitigate these shortcomings, subsequent research integrated temporal modeling directly into model architectures. Prominent methodologies encompass Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks and their variants. Examples include Association LSTM~\cite{Lu_2017_ICCV} for inter-frame feature association, and STMN~\cite{xiaoVideoObjectDetection2018} with its Convolutional Gated Recurrent Unit (ConvGRU) for processing spatio-temporal information from feature maps. Alternative strategies focused on feature filtering. These include techniques like attention mechanisms, for instance, PSLA \cite{guoProgressiveSparseLocal2019}, to weigh feature importance across frames and establish correspondence without computationally expensive optical flow. More recently, Transformer-based architectures \cite{vaswaniAttentionAllYou2023} have exerted considerable influence on object detection. Models such as DETR~\cite{carionEndtoEndObjectDetection2020} and Deformable DETR~\cite{zhuDeformableDETRDeformable2021} reformulated the task as a direct set prediction problem, thereby simplifying operational pipelines. These concepts were extended to the video domain through architectures like TransVOD \cite{zhouTransVODEndtoEndVideo2023} and PTSEFormer \cite{wangPTSEFormerProgressiveTemporalSpatial2022}. By interpreting complex spatio-temporal relationships, capturing multi-scale features, and learning long-range dependencies, these Transformer-based models are among the top-performing models on the ImageNet VOD benchmark~\cite{russakovskyImageNetLargeScale2015}.

% Problem statement -- if necessary, it should include the posed hypothesis/hypotheses, research questions, and subject of research

Despite these advances, a gap remains in developing generalist perception architectures for ADS. Many state-of-the-art models are specialists, with strong inductive biases for specific data types. This limits their flexibility for the diverse sensor modalities (LiDAR, radar, thermal, video) in ADS. They often lack native mechanisms for fusing heterogeneous, high-dimensional inputs without complex, multi-component systems. This highlights the need for general-purpose architectures capable of processing diverse data types without domain-specific assumptions and scaling efficiently, enabling more versatile and robust ADS perception.

% Purpose of the Thesis -- overall aim and objective of the research, "why" of the research—why are you conducting this study?

% novelty

To address these limitations, this thesis introduces novel recurrent architectures, the Recurrent Perceiver (RPerceiver) and its multi-modal variant, Recurrent Perceiver Multi-Modal (RPerceiverMM). These models are designed as highly generalist recurrent modules, inspired by the Perceiver architecture \cite{jaeglePerceiverGeneralPerception2021}, capable of processing diverse and high-dimensional sequential inputs, including multi-sensor data streams. We present a comprehensive training framework and experimental setup specifically designed to assess not only the object detection performance but also the robustness of these architectures against simulated sensor failure scenarios, demonstrating their potential for safety-critical applications like ADS. Our main contributions are as follows:

\begin{itemize}
    \item We propose a Recurrent Perceiver architecture that, when unrolled in time, can be interpreted as a recurrent neural network (RNN). Furthermore, the model supports multiple sensory inputs.
    \item We introduce a novel benchmark dataset, which we call "detection-moving-mnist-easy", designed to evaluate performance on two distinct tasks: bounding box detection and object center point (keypoint) prediction.    
    \item We propose specific training procedures (e.g., input dropout, shuffling) and evaluation protocols designed to simulate and assess model robustness against potential hardware and software failures, such as complete sensor outages or non-deterministic input availability in single-sensor and multi-sensor setups.
\end{itemize}

This thesis is organized as follows: section \ref{Background} provides background information on autonomous driving system architecture, overviews state of the art video object detection approaches, and introduces the original Perceiver model architecture \cite{jaeglePerceiverGeneralPerception2021}. Section \ref{Methods} presents the novel Recurrent Perceiver architecture, introduces the benchmark used for training and testing, and explains the training procedure. Section \ref{Experiments} explains the experiments and presents the results.

% a short overview of appendices including the content of attached materials
% TODO

% TODO: Question where should i put it?
% This thesis was written using the Overleaf1 text editor. The text was checked with the
% Grammarly2 writing assistant to catch typos and other grammatical errors.