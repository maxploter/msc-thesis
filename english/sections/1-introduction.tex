\section{Introduction} \label{Introduction}

% Justification for the choice of topic
% actuality

Autonomous Driving Systems (ADS) promise safer roads, better traffic flow, and reduced environmental impact \cite{litmanAutonomousVehicleImplementationb}. However, achieving this requires ADS to operate reliably under diverse and challenging conditions. Their perception stacks, reliant on multi-sensor data, are vulnerable to hardware and software failures like complete sensor failure or non-deterministic input availability, the two failure modes specifically investigated in this thesis. Such failures can lead to catastrophic accidents, undermining public trust \cite{yurtseverSurveyAutonomousDriving2020}. Therefore, ADS need perception models that support multi-modal hardware and are robust to the failures.

% Overview Theoretical Background -- background information to contextualize the problem
% review of state of the art solutions
Video object detection is a fundamental perception task that has applications in ADS. While video data affords rich spatio-temporal information compared to still images, it also introduces complexities. Initial approaches to the task frequently concentrated on postprocessing the outputs of still-image detectors. These methods employed techniques like non-maximum suppression Seq-NMS~\cite{hanSeqNMSVideoObject2016} to link detections or utilized tracking and optical flow~\cite{kangObjectDetectionVideo2016, kangTCNNTubeletsConvolutional2018} to propagate information for temporal consistency. However, the core still-image detectors of these techniques does not learn from temporal data, and the methods are not end-to-end. This limitation restricts recovery from occlusions or substantial appearance shifts.

To mitigate these shortcomings, subsequent research integrated temporal modeling using Recurrent Neural Networks (RNN) and variants. Examples include Association LSTM~\cite{Lu_2017_ICCV} associates object features between frames, and STMN~\cite{xiaoVideoObjectDetection2018} with its Convolutional Gated Recurrent Unit (ConvGRU) for processing spatio-temporal information from feature maps. Alternative strategies focused on feature filtering, including techniques like attention mechanisms \cite{bahdanauNeuralMachineTranslation2016a}. PSLA~\cite{guoProgressiveSparseLocal2019} weighs feature importance across frames and establishes correspondence without computationally expensive optical flow, by using a special attention approach called progressive sparse stride.

More recently, Transformer-based architectures~\cite{vaswaniAttentionAllYou2023} have emerged as leading models on the ImageNet VOD benchmark~\cite{russakovskyImageNetLargeScale2015}. Models such as DETR~\cite{carionEndtoEndObjectDetection2020} and Deformable DETR~\cite{zhuDeformableDETRDeformable2021} reformulated the object detection task as a direct set prediction problem. These concepts were extended to the video domain through architectures like TransVOD~\cite{zhouTransVODEndtoEndVideo2023} and PTSEFormer~\cite{wangPTSEFormerProgressiveTemporalSpatial2022}, which interpret complex spatio-temporal relationships, capture multi-scale features, and learn long-range dependencies.

% Problem statement -- if necessary, it should include the posed hypothesis/hypotheses, research questions, and subject of research

Despite these advances, a gap remains in developing generalist perception architectures for ADS. Many state-of-the-art models are specialists, with strong inductive biases for specific data types. This limits their flexibility for the diverse sensor modalities (LiDAR, radar, thermal, video) in ADS. They often lack native mechanisms for fusing heterogeneous, high-dimensional inputs without complex, multi-component systems. This highlights the need for general-purpose architectures capable of processing diverse data types without domain-specific assumptions and scaling efficiently, enabling more versatile and robust ADS perception.

% Purpose of the Thesis -- overall aim and objective of the research, "why" of the researchâ€”why are you conducting this study?

% novelty

To address these limitations, this thesis introduces novel recurrent architectures, the Recurrent Perceiver (RPerceiver) and its multi-modal variant, Recurrent Perceiver Multi-Modal (RPerceiverMM). These models are designed as highly generalist recurrent modules, inspired by the Perceiver architecture \cite{jaeglePerceiverGeneralPerception2021}, capable of processing diverse and high-dimensional sequential inputs, including multi-sensor data streams. We present a comprehensive training framework and experimental setup specifically designed to assess not only the object detection performance but also the robustness of these architectures against simulated sensor failure scenarios, demonstrating their potential for safety-critical applications like ADS. Main contributions are as follows:

\begin{itemize}
    \item A Recurrent Perceiver architecture is proposed that, when unrolled in time, can be interpreted as RNN. Furthermore, the model supports multiple sensory inputs.
    \item A novel benchmark dataset, "detection-moving-mnist-easy", is introduced, designed to evaluate performance on two distinct tasks: bounding box detection and object center point (keypoint) prediction.
    \item Specific training procedures (e.g. input dropout, shuffling) and evaluation protocols designed to simulate and assess model robustness against potential hardware and software failures, such as complete sensor outages or non-deterministic input availability in single-sensor and multi-sensor setups, are proposed.
\end{itemize}

This thesis is organized as follows: section \ref{Background} provides background information on autonomous driving system architecture, overviews state of the art video object detection approaches, and introduces the original Perceiver model architecture \cite{jaeglePerceiverGeneralPerception2021}. Section \ref{Methods} presents the novel Recurrent Perceiver architecture, introduces the benchmark used for training and testing, and explains the training procedure. Section \ref{Experiments} explains the experiments and presents the results.

% a short overview of appendices including the content of attached materials
% TODO

% TODO: Question where should i put it?
% This thesis was written using the Overleaf1 text editor. The text was checked with the
% Grammarly2 writing assistant to catch typos and other grammatical errors.