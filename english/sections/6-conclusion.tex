\section{Conclusion} \label{Conclusion}

Two novel architectures were introduced: the Recurrent Perceiver (RPerceiver) and its multi-modal variant (RPerceiverMM). These were inspired by the Perceiver architecture's \cite{jaeglePerceiverGeneralPerception2021} ability to handle high-dimensional, multi-modal data but were adapted for sequential inputs, such as video. To facilitate this research, a novel dataset, "detection-moving-mnist-easy", was generated. This dataset provides controlled video sequences with annotations for evaluating both bounding box and center point (keypoint) prediction tasks.

The RPerceiver was compared against a strong baseline, YOLOv8n \cite{Jocher_Ultralytics_YOLO_2023}, on the bounding box detection task.
While both models showed similar $mAP@0.5$ and $mAP@0.75$ scores, YOLOv8n performed better at $mAP@0.5:0.95$. Further evaluation showed that YOLOv8n performed better with overlapping objects when the $\mathrm{IoU}$ between objects was $> 10\%$. However, the RPerceiver demonstrated superior performance in handling objects near frame borders, suggesting its effectiveness in leveraging temporal information, particularly when objects have partial visibility.
Notably, RPerceiver achieved competitive mAP scores with significantly fewer parameters and lower computational cost compared to YOLOv8n.

Another contribution of this work was the investigation of training strategies to enhance model resilience against sensor input degradation, simulating real-world Autonomous Driving Systems (ADS) challenges like complete sensor failure and asynchronous data arrival.
\texttt{dropout} and \texttt{shuffle} training procedures were introduced and evaluated.
Ablation studies using the center point prediction task demonstrated the efficacy of these strategies. In single-view scenarios, training RPerceiver with \texttt{dropout} resulted in significantly better performance under simulated complete sensor failure compared to the baseline model, although it incurred a minor performance penalty under normal conditions.

Extending the analysis to multi-view scenarios using RPerceiverMM, the benefits of targeted training procedures were further confirmed. Models trained with input \texttt{shuffling} excelled when evaluated with shuffled sensor inputs, while \texttt{dropout}-trained models showed the best robustness against simulated sensor failure.
The model trained with both \texttt{dropout} and \texttt{shuffling} provided the most robust performance under the combined \texttt{blind, shuffle} evaluation, highlighting the potential for tailoring training methods to specific anticipated failure modes.
While these robustness-enhancing training procedures introduced a slight performance decrease under default, non-degraded conditions, they offer substantial improvements in resilience against common sensor issues faced by ADS.
