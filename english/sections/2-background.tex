\section{Background}  \label{Background}

\subsection{Autonomous Driving Systems} \label{Background:ADS}

The Society of Automotive Engineers (SAE) defines Autonomous Driving Systems (ADS) as the hardware and software that are collectively capable of performing the entire dynamic driving task (DDT) on a sustained basis, regardless of whether it is limited to a specific operational design domain (ODD) \cite{sae:j3016:2021apr}. ADS term is used to describe the last three and the most advanced levels of ADS automation Level 3, 4, and 5.

There's an expectation of 

State-of-the-art ADS employ a wide variety of sensors, often with redundancy, to ensure safety. These sensors can be categorized based on their purpose. In this thesis, we focus on exteroceptive sensors, which are primarily used for perceiving the surrounding environment to accomplish tasks necessary for the ADS.





% goal: explain relevance between ADS and video object detection task

Autonomous vehicle are complex on multi-sensor perception, integrating data from various sources such as LiDAR, cameras, and radar to create a comprehensive understanding of the environment.

Definition of autonomous driving systems. Explain architecture.

Type of sensors in ADS.

\subsection{Sensors} \label{Background:Sensors}

% goal: explain relevance between sensors and video object detection task


\subsection{Video Object Detection} \label{Background:VideoObjectDetection}

% Object detection definition. Deep learning pushed performance of single image object detection.

Object detection is a foundational challenge in computer vision and has been a subject of research for several decades \cite{fischlerRepresentationMatchingPictorial1973}. The goal of the object detection task is to find object(s) of given description in images and videos. Advancements in deep learning techniques to learn feature representations \cite{hintonReducingDimensionalityData2006, lecunDeepLearning2015} have made it possible to achive remarkable progress in single-image object detectors \cite{girshickRichFeatureHierarchies2014a}.

% State-of-the-Art
% Still-image detector

Due to similarity beetwen object detection on image and video, the simplest approach to tackle a video object detection is to use a single-image object detector, so treat each video frame as an independent image. However, this approach is naive because it completely ignores temporal and contextual information of the video. A still image detector is not able to consistently predict objects acrsso all video frames due to numerouse artefactos and biases in the video (e.g., motion blur, occlusion, unusual position).

% Postprocessing (not e2e)

%One intuition to improve temporal consistency is to propagate detection results to neighbor frames to reduce sudden changes of detection results.

%In this work we propose a simple extension of single image object detection to help overcome these difficulties.

Another simple approach which improves temporal consistency of video object detections involves a postprocessing step after still image detector \cite{hanSeqNMSVideoObject2016, kangTCNNTubeletsConvolutional2018, kangObjectDetectionVideo2016}. Detections from adjecent frames are used to improve results of the current frame. At postprocessing step researches apply technich like non-maximum suppression (NMS) \cite{hanSeqNMSVideoObject2016} or optical flow \cite{kangTCNNTubeletsConvolutional2018, kangObjectDetectionVideo2016}. Although these methods show improvement over a stil image detector aproach, exploiting temporal information as postprocessing is sub-optimal since temporal and motion information are ignored during detector training.

% TODO: paper Multi-Class Multi-Object Tracking using  Changing Point Detection

% VIDEO DETECTION WITH ADDITIONAL MODELS

Another approach suggests to introduce motion and temporal information during training to form an end-to-end solution. In \cite{Lu_2017_ICCV} proposed to use a LSTM \cite{6795963} to refine the detection results together with association features which representation of the detected objects. This model is end-to-end and can be trained jointly with the object detector. This algorithm rely on objects association between adjacent frames therefore it is limited to short-term motion information and cannot handle long occlusions or unusual appearance of for a long time which is the same problem with algorithms based on postprocessing. Another work proposes a recurrent computation unit called spatial-temporal memory module (STMM) \cite{xiaoVideoObjectDetection2018} which uses a ConvGRU \cite{ballasDelvingDeeperConvolutional2016} to preserve a spacio temporal structure and show suggests the effectiveness of our memory: the longer the sequence, the more longer-range useful information is stored in the memory, which leads to better detection performance.

% Transformers

Transformers [32], [33], [34], [35], [36] have shown promising potential in computer vision. Especially, DETR [33], [34] simplifies the detection pipeline by modeling the object queries and achieving comparative performance with highly optimized CNN-based detectors.

Thus, it is in desperate need to build a simple yet effective VOD framework in a fully end-to-end manner.

\subsection{General purpose Perceiver model} \label{Background:VideoObjectDetection}